{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446a1c81",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8f9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de72b22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'm5-forecasting-accuracy',\n",
       " 'm5-forecasting-accuracy.zip',\n",
       " 'Trading_at_Close']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./Dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd6cf4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Dataset/Trading_at_Close/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8c03076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'test.csv', 'train.csv', 'test.csv.zip', 'train.csv.zip']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8be2176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from numpy.random import rand\n",
    "from numpy.random import choice\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4764eb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d065f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{data_path}/train.csv')\n",
    "df_test = pd.read_csv(f'{data_path}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a13ad59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "1                       -1         0.999896    1642214.25        NaN   \n",
       "2                       -1         0.999561    1819368.03        NaN   \n",
       "3                       -1         1.000171   18389745.62        NaN   \n",
       "4                       -1         0.999532   17860614.95        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "\n",
       "   time_id row_id  \n",
       "0        0  0_0_0  \n",
       "1        0  0_0_1  \n",
       "2        0  0_0_2  \n",
       "3        0  0_0_3  \n",
       "4        0  0_0_4  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d1b677d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>currently_scored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>3753451.43</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>11548975.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>22940.00</td>\n",
       "      <td>1.000050</td>\n",
       "      <td>9177.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>985977.11</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000245</td>\n",
       "      <td>3850033.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>1967.90</td>\n",
       "      <td>1.000601</td>\n",
       "      <td>19692.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>599128.74</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000584</td>\n",
       "      <td>4359198.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>4488.22</td>\n",
       "      <td>1.000636</td>\n",
       "      <td>34955.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>2872317.54</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>27129551.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>16082.04</td>\n",
       "      <td>1.000189</td>\n",
       "      <td>10314.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>740059.14</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>8880890.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>19012.35</td>\n",
       "      <td>1.000107</td>\n",
       "      <td>7245.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26290</td>\n",
       "      <td>478_0_4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0      478                  0      3753451.43   \n",
       "1         1      478                  0       985977.11   \n",
       "2         2      478                  0       599128.74   \n",
       "3         3      478                  0      2872317.54   \n",
       "4         4      478                  0       740059.14   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                       -1         0.999875   11548975.43        NaN   \n",
       "1                       -1         1.000245    3850033.97        NaN   \n",
       "2                        1         1.000584    4359198.25        NaN   \n",
       "3                       -1         0.999802   27129551.64        NaN   \n",
       "4                       -1         0.999886    8880890.78        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price  ask_size  wap  time_id  \\\n",
       "0         NaN   0.999875  22940.00   1.000050   9177.60  1.0    26290   \n",
       "1         NaN   0.999940   1967.90   1.000601  19692.00  1.0    26290   \n",
       "2         NaN   0.999918   4488.22   1.000636  34955.12  1.0    26290   \n",
       "3         NaN   0.999705  16082.04   1.000189  10314.00  1.0    26290   \n",
       "4         NaN   0.999720  19012.35   1.000107   7245.60  1.0    26290   \n",
       "\n",
       "    row_id  currently_scored  \n",
       "0  478_0_0             False  \n",
       "1  478_0_1             False  \n",
       "2  478_0_2             False  \n",
       "3  478_0_3             False  \n",
       "4  478_0_4             False  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a13cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "far_price_mean = df_train.groupby('stock_id')['far_price'].mean()\n",
    "near_price_mean = df_train.groupby('stock_id')['near_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "459e0d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.far_price.isna(),'far_price'] = df_train.loc[df_train.far_price.isna()]['stock_id'].map(far_price_mean)\n",
    "df_train.loc[df_train.near_price.isna(),'near_price'] = df_train.loc[df_train.near_price.isna()]['stock_id'].map(near_price_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "182e8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na Test , avg from Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c3df23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test.far_price.isna(),'far_price'] = df_test.loc[df_test.far_price.isna()]['stock_id'].map(far_price_mean)\n",
    "\n",
    "df_test.loc[df_test.near_price.isna(),'near_price'] = df_test.loc[df_test.near_price.isna()]['stock_id'].map(near_price_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "568c5d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                   0.000000\n",
       "date_id                    0.000000\n",
       "seconds_in_bucket          0.000000\n",
       "imbalance_size             0.000042\n",
       "imbalance_buy_sell_flag    0.000000\n",
       "reference_price            0.000042\n",
       "matched_size               0.000042\n",
       "far_price                  0.000000\n",
       "near_price                 0.000000\n",
       "bid_price                  0.000042\n",
       "bid_size                   0.000000\n",
       "ask_price                  0.000042\n",
       "ask_size                   0.000000\n",
       "wap                        0.000042\n",
       "target                     0.000017\n",
       "time_id                    0.000000\n",
       "row_id                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dbd6e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6eaed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "492e1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import statistics\n",
    "from sklearn.metrics import make_scorer # to define custom loss function \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a974ee",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ec1ad936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "custom_loss_rmse =lambda y_true, y_pred: (mean_squared_error(y_true,y_pred))**0.5\n",
    "custom_loss_mse = lambda y_true, y_pred: mean_squared_error(y_true,y_pred)\n",
    "custom_loss_mae = lambda y_true, y_pred:mean_absolute_error(y_true,y_pred)\n",
    "custom_loss_mape = lambda y_true, y_pred:mean_absolute_percentage_error(y_true,y_pred)\n",
    "r2 = lambda y_true, y_pred:r2_score(y_true,y_pred)\n",
    "loss_map = {'rmse':custom_loss_rmse, 'mse':custom_loss_mse,'mape':custom_loss_mape, 'mae':custom_loss_mae,'r2':r2,'max_error':'max_error'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16ff21",
   "metadata": {},
   "source": [
    "# Feature Selection with Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f65b3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "82583670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_population(population_size,num_features):\n",
    "    population = []\n",
    "    max_features = round(0.95*num_features)\n",
    "    for i in range(population_size):\n",
    "        individual = [True]*random.randrange(max_features)\n",
    "        f_c = [False]*(num_features-(len(individual)))\n",
    "        individual.extend(f_c)\n",
    "        random.shuffle(individual)\n",
    "      #individual = list(choice([True, False], size=num_features))\n",
    "        while individual in population:\n",
    "            individual = [True]*random.randrange(max_features)\n",
    "            f_c = [False]*(num_features-(len(individual)))\n",
    "            individual.extend(f_c)\n",
    "            random.shuffle(individual)\n",
    "      #Edge Case: if all genes are 0, then we will make any one gene as 1 \n",
    "      # ( this will ensure atleast one feature in solution)\n",
    "        if(sum(individual)==0):\n",
    "            position = random.randrange(num_features)\n",
    "            individual[position] = True\n",
    "        population.append(individual)\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fada2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitness(population,X,y,estimator,loss):\n",
    "    fitness_values = []\n",
    "    for individual in population:\n",
    "        ix = [i for i, x in enumerate(individual) if x]\n",
    "        X_new = X.iloc[:, ix].copy()\n",
    "        y = y.copy()\n",
    "        individual_fitness = calculate_fitness(X_new,y,estimator,loss)\n",
    "        fitness_values.append(individual_fitness)\n",
    "    return fitness_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7c3076aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "def calculate_fitness(X,y,estimator=RandomForestRegressor(random_state=42), loss = 'rmse'):\n",
    "    \"\"\"X is train data subset with selected feature use custome scorer for regression to by pass higher the better condition\n",
    "      default loss is MAE \"\"\"\n",
    "    X = X.copy()\n",
    "    y = y.copy()\n",
    "    #score = make_scorer(loss_map.get(loss,custom_loss_mae), greater_is_better=False)\n",
    "    #score is -ve for CV optimization \n",
    "    # scores in cross_val_score \n",
    "    tscv = TimeSeriesSplit(n_splits = 5)\n",
    "    scores = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        cv_train, cv_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        #print(cv_test.shape)\n",
    "        y_train,y_test = y.iloc[train_index],y.iloc[test_index]\n",
    "        model = estimator.fit(cv_train,y_train)\n",
    "        predictions = model.predict(cv_test)\n",
    "        scores.append((loss_map[loss](y_test, predictions)))\n",
    "      # scorer = loss_map.get(loss,'neg_mean_absolute_error')\n",
    "      # scores = cross_val_score(estimator,X,y,scoring=scorer,n_jobs=-1,cv=10) \n",
    "    return 1/np.mean((scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fad728ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parents(population,n_parents, fitness_values):\n",
    "    \"\"\"steps for Roulette Wheel Selection\n",
    "    [Sum] Calculate the sum of all chromosome fitnesses in population - sum S.\n",
    "    [Select] Generate random number from the interval (0,S) - r.\n",
    "    [Loop] Go through the population and sum the fitnesses from 0 - sum s. When the sum s is greater then r, stop and return the chromosome where you are.\n",
    "    the step 1 is performed only once for each population.\n",
    "    1. Calculate S = the sum of a finesses.\n",
    "    2. Generate a random number R between 0 and S.\n",
    "    3. Starting from the top of the population, keep adding the fitnesses to the partial sum P, till P less than R.\n",
    "    4. The individual for which P exceeds R is the chosen individual. \n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    # Elitism pick top parents as is for next generation\n",
    "    ind = pd.Series(fitness_values).argsort()[::-1]\n",
    "    elit = round(n_parents*0.01)\n",
    "    indx = ind[:elit]\n",
    "    elit_parents = []\n",
    "    for i in indx:\n",
    "        elit_parents.append(population[i])\n",
    "    parents.extend(elit_parents)\n",
    "    total = sum(fitness_values) # S\n",
    "    norm_fitness_values = pd.Series(fitness_values)/total # relative fitness\n",
    "    cumulative_fitness = norm_fitness_values.cumsum()\n",
    "    population_size = len(population)\n",
    "    for count in range(round(n_parents*0.9)):\n",
    "        random_number = random.uniform(0, 1) # R random number from 0,S or 1 in case on normalized scores\n",
    "        individual_number = 0\n",
    "        for score in cumulative_fitness:\n",
    "            if(random_number <= score):\n",
    "                id_ = population[individual_number]\n",
    "                parents.append(id_)\n",
    "                break\n",
    "            individual_number+=1   \n",
    "        \n",
    "    return parents,elit_parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c9b1cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_point_crossover(parents,probability):\n",
    "    \"\"\"In this one-point crossover, a random crossover point is selected and the tails of its two parents are swapped to get new off-springs \"\"\"\n",
    "    chromosome_len = len(parents[0])\n",
    "    crossover_population = []\n",
    "    no_of_pairs = round(len(parents)/2)\n",
    "    for num in range(no_of_pairs):\n",
    "        length = len(parents)\n",
    "        parent1_index, parent2_index = random.sample(range(length), k=2)\n",
    "        parent1 = parents[parent1_index]\n",
    "        parent2 = parents[parent2_index]\n",
    "        if random.uniform(0,1)<probability: \n",
    "            crossover_point = random.randrange(chromosome_len)\n",
    "            child1 = parent1[:crossover_point]\n",
    "            child1.extend(parent2[crossover_point:])\n",
    "            child2 = parent1[:crossover_point]\n",
    "            child2.extend(parent2[crossover_point:])\n",
    "            parents.remove(parent1)\n",
    "            parents.remove(parent2)\n",
    "            if sum(child1)>0:\n",
    "                crossover_population.append(child1)\n",
    "            if sum(child2)>0:\n",
    "                crossover_population.append(child2)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if(len(parents)>0):\n",
    "        crossover_population.extend(parents)\n",
    "    return crossover_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680585f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4a44c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_crossover(parents,probability):\n",
    "    \"\"\"In a uniform crossover, we don’t divide the chromosome into segments, rather we treat each gene separately. In this, we essentially flip a coin for each chromosome to decide whether or not it’ll be included in the off-spring. We can also bias the coin to one parent, to have more genetic material in the child from that parent.\n",
    "  Usually, a probability is assigned to this process, indicating the chance of crossover for a given pair. Crossover is a high probability event and is assigned an optimum probability between 0.65–0.80. Here, I have used a probability of 0.78.\n",
    "  \"\"\"\n",
    "    random.shuffle(parents)\n",
    "    crossover_population = []\n",
    "    chromosome_len = len(parents[0])\n",
    "    no_of_pairs = round(len(parents)/2)\n",
    "    for num in range(no_of_pairs):\n",
    "        length = len(parents)\n",
    "        parent1_index, parent2_index = random.sample(range(length), k=2)\n",
    "        parent1 = parents[parent1_index]\n",
    "        parent2 = parents[parent2_index]\n",
    "        if random.uniform(0,1)<=probability: \n",
    "            swap = [rand()<0.5 for i in range(chromosome_len)]\n",
    "            child1 = [parent1[i] if j else parent2[i] for i,j in enumerate(swap)]\n",
    "            child2 = [parent2[i] if j else parent1[i] for i,j in enumerate(swap)]\n",
    "            parents.remove(parent1)\n",
    "            parents.remove(parent2)\n",
    "            if sum(child1)>0:\n",
    "                crossover_population.append(child1)\n",
    "            if sum(child2)>0:\n",
    "                crossover_population.append(child2)\n",
    "        else:\n",
    "            pass\n",
    "    if(len(parents)>0):\n",
    "        crossover_population.extend(parents)\n",
    "    return crossover_population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b02fc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(crossover_population):\n",
    "    for individual in crossover_population:\n",
    "        index_1, index_2 = random.sample(range(len(individual)), k=2)\n",
    "        #swapping the bits\n",
    "        individual[index_1],individual[index_2] = individual[index_2],individual[index_1]\n",
    "    return crossover_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0753499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "92132fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_feature_selection(X,y,n_gen, mutation_prob=0.005, estimator=RandomForestRegressor(random_state=42), loss='mae'):\n",
    "    best_fitness_chromosome = {}\n",
    "    X = X.copy()\n",
    "    y = y.copy()\n",
    "    num_features = X.shape[1]\n",
    "    population_size = round(2*num_features)\n",
    "    n_parents = round(population_size*3/4)\n",
    "    # init population\n",
    "    population = init_population(population_size,num_features)\n",
    "    print(\"generated population of size\",len(population))\n",
    "    # calculate fitness value of population\n",
    "    fitness_values = get_fitness(population,X,y,estimator,loss)\n",
    "    parents,elit_parents = select_parents(population,n_parents, fitness_values)\n",
    "    best_fitness_chromosome['init'] = population[pd.Series(fitness_values).argmax()]\n",
    "    crossover_population = uniform_crossover(parents,0.8)\n",
    "    #crossover_population = one_point_crossover(parents,0.85)\n",
    "    population = crossover_population\n",
    "    p = random.uniform(0,1)\n",
    "    \n",
    "    if p < mutation_prob:\n",
    "        mutated_population = mutation(crossover_population)\n",
    "        population = mutated_population\n",
    "    fitness_values = get_fitness(population,X,y,estimator,loss)\n",
    "    best_fitness_chromosome['gen0'] = population[pd.Series(fitness_values).argmax()]\n",
    "    variance_of_population = statistics.variance(1/pd.Series(fitness_values))\n",
    "    print(f\"starting variance is={variance_of_population}\",)\n",
    "    gen = 1\n",
    "    best_chromosome_fitness = {}\n",
    "    elit_pop = {}\n",
    "    threshold = 0.001\n",
    "  \n",
    "    #for i in range(n_gen):\n",
    "    while (variance_of_population > threshold) and gen < n_gen  :\n",
    "        print(f'generation-{gen}')\n",
    "        parents,elit_parents = select_parents(population,n_parents,fitness_values)\n",
    "        elit_pop[f'gen{gen}'] = list(pd.DataFrame(elit_parents).T.sum(axis=1))\n",
    "        crossover_population = uniform_crossover(parents,0.7)\n",
    "        #crossover_population = one_point_crossover(parents,0.85)\n",
    "        population = crossover_population\n",
    "        p = random.uniform(0,1)\n",
    "        if(p<=mutation_prob): #mutation prob here\n",
    "            mutated_population = mutation(crossover_population)\n",
    "            population = mutated_population\n",
    "        fitness_values = get_fitness(population,X,y,estimator,loss)\n",
    "        best_fiteness =1/fitness_values[pd.Series(fitness_values).argmax()]\n",
    "        best_chro = population[pd.Series(fitness_values).argmax()]\n",
    "        best_fitness_chromosome[f'gen{gen}'] = best_chro\n",
    "        best_chromosome_fitness[f'gen{gen}'] = best_fiteness\n",
    "        variance_of_population = statistics.variance(1/pd.Series(fitness_values))\n",
    "        acc_score_population = np.mean(fitness_values)\n",
    "        print(f\"num_features in best chromosome = {sum(best_chro)} variance is= {variance_of_population}, avg {loss} = {round(1/acc_score_population)}, best = {round(best_fiteness)}\")\n",
    "        gen+=1\n",
    "    best_features = []\n",
    "    best_acc_score = 0\n",
    "    avg_fitness = sum(fitness_values)/len(fitness_values)\n",
    "    #avg_fitness_2 = sum(1/fitness_values)/len(fitness_values)\n",
    "    avg_fitness_2 = 1/(avg_fitness)\n",
    "    index = (pd.Series(fitness_values)).argmax()\n",
    "    fitness_value = fitness_values[index]\n",
    "  \n",
    "    print(f'avg fitness is:{avg_fitness}, {avg_fitness_2}, best fitness is: {round(1/fitness_value,2)}')\n",
    "   \n",
    "    best_features = population[index]\n",
    "    best_acc_score = fitness_value\n",
    "  \n",
    "\n",
    "    return best_features,best_acc_score#, best_fitness_chromosome,best_chromosome_fitness,elit_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2016618a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a51b5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_id = random.choice(df_train['stock_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ea850681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tmp =df_train[df_train['stock_id']==stock_id].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3a6a4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train_ Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8aadeb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9111ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_Val = train_test_split(df_train_tmp,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ae49aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['target']\n",
    "X_train = X_train[['seconds_in_bucket', 'imbalance_size',\n",
    "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
    "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
    "       'ask_size', 'wap']].copy()\n",
    "\n",
    "v_val = X_Val['target']\n",
    "X_Val = X_Val[['seconds_in_bucket', 'imbalance_size',\n",
    "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
    "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
    "       'ask_size', 'wap']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc79eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated population of size 24\n",
      "starting variance is=0.2342611661237598\n",
      "generation-1\n",
      "num_features in best chromosome = 7 variance is= 0.2384320464879258, avg rmse = 8, best = 7\n",
      "generation-2\n",
      "num_features in best chromosome = 7 variance is= 0.23410031533019668, avg rmse = 8, best = 7\n",
      "generation-3\n",
      "num_features in best chromosome = 7 variance is= 0.11294582425505671, avg rmse = 8, best = 7\n",
      "generation-4\n",
      "num_features in best chromosome = 7 variance is= 0.23591343404217968, avg rmse = 8, best = 7\n",
      "generation-5\n",
      "num_features in best chromosome = 7 variance is= 0.026044438394346718, avg rmse = 8, best = 7\n",
      "generation-6\n"
     ]
    }
   ],
   "source": [
    "best_features,best_acc_score = GA_feature_selection(X_train,y_train,n_gen=20,estimator=RandomForestRegressor(random_state=57, n_estimators=100),loss='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "250698a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features::  Index(['seconds_in_bucket', 'imbalance_size', 'matched_size', 'near_price',\n",
      "       'bid_size', 'ask_size', 'wap'],\n",
      "      dtype='object') from list : Index(['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
      "       'reference_price', 'matched_size', 'far_price', 'near_price',\n",
      "       'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Selected features:: ', X_train.columns[best_features], 'from list :',X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b166d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = list(X_train.columns[best_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "988a22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e87ac30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aa744749",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b57827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
